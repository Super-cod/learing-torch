{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-24T21:34:59.466683Z",
     "start_time": "2025-07-24T21:34:59.451001Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from kagglehub import dataset_load\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader,dataset\n",
    "from PIL import Image\n",
    "import spacy"
   ],
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:34:59.856502Z",
     "start_time": "2025-07-24T21:34:59.514113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# It's good practice to load the spacy model once globally\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self, frequency_threshold):\n",
    "        # Initial tokens\n",
    "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\",}\n",
    "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3,}\n",
    "        self.frequency_threshold = frequency_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenizer_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = {}\n",
    "        idx = 4  # Start index after special tokens\n",
    "\n",
    "        # Step 1: Count all word frequencies across all sentences\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer_eng(sentence):\n",
    "                frequencies[word] = frequencies.get(word, 0) + 1\n",
    "\n",
    "        # Step 2: Add words to vocab if they meet the frequency threshold\n",
    "        for word, count in frequencies.items():\n",
    "            if count >= self.frequency_threshold:\n",
    "                self.stoi[word] = idx\n",
    "                self.itos[idx] = word\n",
    "                idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer_eng(text)\n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
    "            for token in tokenized_text\n",
    "        ]"
   ],
   "id": "2162c1aebe3330d2",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:34:59.917788Z",
     "start_time": "2025-07-24T21:34:59.902251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FlickerDataset(Dataset):\n",
    "    def __init__(self, root_dir, caption_file, vocab, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(caption_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Use the vocabulary passed as an argument\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.images = self.df[\"images\"]\n",
    "        self.captions = self.df[\"caption\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            img_path = os.path.join(self.root_dir, self.df.iloc[index, 0])\n",
    "            caption = self.df.iloc[index, 1]\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n",
    "            numericalized_caption += self.vocab.numericalize(caption)\n",
    "            numericalized_caption.append(self.vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "            return image,torch.tensor(numericalized_caption)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error at index {index} — {self.df.iloc[index, 0]}\")\n",
    "            raise e\n"
   ],
   "id": "69ba3bc672eaa4f5",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:34:59.985596Z",
     "start_time": "2025-07-24T21:34:59.965303Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa371622b5dc220d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:00.048687Z",
     "start_time": "2025-07-24T21:35:00.032989Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "388be36ec35fd9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:00.105388Z",
     "start_time": "2025-07-24T21:35:00.089325Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()\n",
   "id": "aa7fec4cb1811811",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           images                                            caption\n",
       "1  1000092795.jpg   Two young guys with shaggy hair look at their...\n",
       "2  1000092795.jpg   Two young , White males are outside near many...\n",
       "3  1000092795.jpg   Two men in green shirts are standing in a yard .\n",
       "4  1000092795.jpg       A man in a blue shirt standing in a garden .\n",
       "5  1000092795.jpg            Two friends enjoy time spent together ."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 198
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:02.533486Z",
     "start_time": "2025-07-24T21:35:02.297609Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"captions.csv\", index=False)\n",
   "id": "6b20a4c12ad9bf5e",
   "outputs": [],
   "execution_count": 199
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:02.622857Z",
     "start_time": "2025-07-24T21:35:02.607208Z"
    }
   },
   "cell_type": "code",
   "source": "voab=Vocabulary(10)",
   "id": "ad4fe8a370ddedd0",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.001740Z",
     "start_time": "2025-07-24T21:35:02.717683Z"
    }
   },
   "cell_type": "code",
   "source": "voab.build_vocabulary(caption_list)",
   "id": "83a62f8d4322453d",
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.082072Z",
     "start_time": "2025-07-24T21:35:19.051653Z"
    }
   },
   "cell_type": "code",
   "source": "caption_list=df[\"caption\"].dropna().astype(str).tolist()",
   "id": "b7ca919458c4835c",
   "outputs": [],
   "execution_count": 202
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.145730Z",
     "start_time": "2025-07-24T21:35:19.129714Z"
    }
   },
   "cell_type": "code",
   "source": "len(caption_list)",
   "id": "19a5348093563a26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158914"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 203
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.222262Z",
     "start_time": "2025-07-24T21:35:19.194610Z"
    }
   },
   "cell_type": "code",
   "source": "voab.itos",
   "id": "c5ba45953eb0ff6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<SOS>',\n",
       " 2: '<EOS>',\n",
       " 3: '<UNK>',\n",
       " 4: ' ',\n",
       " 5: 'two',\n",
       " 6: 'young',\n",
       " 7: 'guys',\n",
       " 8: 'with',\n",
       " 9: 'shaggy',\n",
       " 10: 'hair',\n",
       " 11: 'look',\n",
       " 12: 'at',\n",
       " 13: 'their',\n",
       " 14: 'hands',\n",
       " 15: 'while',\n",
       " 16: 'hanging',\n",
       " 17: 'out',\n",
       " 18: 'in',\n",
       " 19: 'the',\n",
       " 20: 'yard',\n",
       " 21: '.',\n",
       " 22: ',',\n",
       " 23: 'white',\n",
       " 24: 'males',\n",
       " 25: 'are',\n",
       " 26: 'outside',\n",
       " 27: 'near',\n",
       " 28: 'many',\n",
       " 29: 'bushes',\n",
       " 30: 'men',\n",
       " 31: 'green',\n",
       " 32: 'shirts',\n",
       " 33: 'standing',\n",
       " 34: 'a',\n",
       " 35: 'man',\n",
       " 36: 'blue',\n",
       " 37: 'shirt',\n",
       " 38: 'garden',\n",
       " 39: 'friends',\n",
       " 40: 'enjoy',\n",
       " 41: 'time',\n",
       " 42: 'together',\n",
       " 43: 'several',\n",
       " 44: 'hard',\n",
       " 45: 'hats',\n",
       " 46: 'operating',\n",
       " 47: 'giant',\n",
       " 48: 'pulley',\n",
       " 49: 'system',\n",
       " 50: 'workers',\n",
       " 51: 'down',\n",
       " 52: 'from',\n",
       " 53: 'up',\n",
       " 54: 'above',\n",
       " 55: 'on',\n",
       " 56: 'piece',\n",
       " 57: 'of',\n",
       " 58: 'equipment',\n",
       " 59: 'working',\n",
       " 60: 'machine',\n",
       " 61: 'wearing',\n",
       " 62: 'four',\n",
       " 63: 'top',\n",
       " 64: 'tall',\n",
       " 65: 'structure',\n",
       " 66: 'three',\n",
       " 67: 'large',\n",
       " 68: 'rig',\n",
       " 69: 'child',\n",
       " 70: 'pink',\n",
       " 71: 'dress',\n",
       " 72: 'is',\n",
       " 73: 'climbing',\n",
       " 74: 'set',\n",
       " 75: 'stairs',\n",
       " 76: 'an',\n",
       " 77: 'entry',\n",
       " 78: 'way',\n",
       " 79: 'little',\n",
       " 80: 'girl',\n",
       " 81: 'going',\n",
       " 82: 'into',\n",
       " 83: 'wooden',\n",
       " 84: 'cabin',\n",
       " 85: 'to',\n",
       " 86: 'her',\n",
       " 87: 'playhouse',\n",
       " 88: 'building',\n",
       " 89: 'someone',\n",
       " 90: 'and',\n",
       " 91: 'hat',\n",
       " 92: 'stair',\n",
       " 93: 'leaning',\n",
       " 94: 'against',\n",
       " 95: 'window',\n",
       " 96: 'ladder',\n",
       " 97: 'cleaning',\n",
       " 98: 'cleans',\n",
       " 99: 'jeans',\n",
       " 100: 'windows',\n",
       " 101: 'one',\n",
       " 102: 'gray',\n",
       " 103: 'black',\n",
       " 104: 'stove',\n",
       " 105: 'guy',\n",
       " 106: 'cooking',\n",
       " 107: 'around',\n",
       " 108: 'camera',\n",
       " 109: 'kitchen',\n",
       " 110: 'food',\n",
       " 111: 'preparing',\n",
       " 112: 'meal',\n",
       " 113: 'people',\n",
       " 114: 'photo',\n",
       " 115: 'playing',\n",
       " 116: 'guitar',\n",
       " 117: 'other',\n",
       " 118: 'poking',\n",
       " 119: 'him',\n",
       " 120: 'holds',\n",
       " 121: 'observes',\n",
       " 122: 'his',\n",
       " 123: 'fixing',\n",
       " 124: 'players',\n",
       " 125: 'costume',\n",
       " 126: 'another',\n",
       " 127: \"'s\",\n",
       " 128: 'coat',\n",
       " 129: 'boys',\n",
       " 130: 'sits',\n",
       " 131: 'chair',\n",
       " 132: 'holding',\n",
       " 133: 'stuffed',\n",
       " 134: 'animal',\n",
       " 135: 'lion',\n",
       " 136: 'sitting',\n",
       " 137: 'completes',\n",
       " 138: 'finishing',\n",
       " 139: 'touches',\n",
       " 140: 'toy',\n",
       " 141: 'smiling',\n",
       " 142: 'rollerskates',\n",
       " 143: 'talking',\n",
       " 144: 'cellphone',\n",
       " 145: 'parking',\n",
       " 146: 'lot',\n",
       " 147: 'trendy',\n",
       " 148: 'gliding',\n",
       " 149: 'slowly',\n",
       " 150: 'street',\n",
       " 151: 'adult',\n",
       " 152: 'rollerblades',\n",
       " 153: 'cellular',\n",
       " 154: 'phone',\n",
       " 155: 'ear',\n",
       " 156: 'there',\n",
       " 157: 'skating',\n",
       " 158: 'woman',\n",
       " 159: 'asian',\n",
       " 160: 'suit',\n",
       " 161: 'stands',\n",
       " 162: 'dark',\n",
       " 163: '-',\n",
       " 164: 'haired',\n",
       " 165: 'brown',\n",
       " 166: 'pipes',\n",
       " 167: 'metal',\n",
       " 168: 'railing',\n",
       " 169: 'walks',\n",
       " 170: 'past',\n",
       " 171: 'dressed',\n",
       " 172: 'hip',\n",
       " 173: 'outfits',\n",
       " 174: 'purse',\n",
       " 175: 'walking',\n",
       " 176: 'by',\n",
       " 177: 'gate',\n",
       " 178: 'jumping',\n",
       " 179: 'over',\n",
       " 180: 'rail',\n",
       " 181: 'same',\n",
       " 182: 'without',\n",
       " 183: 'youths',\n",
       " 184: 'roadside',\n",
       " 185: 'night',\n",
       " 186: 'dancing',\n",
       " 187: 'poles',\n",
       " 188: 'middle',\n",
       " 189: 'no',\n",
       " 190: 'five',\n",
       " 191: 'ballet',\n",
       " 192: 'dancers',\n",
       " 193: 'caught',\n",
       " 194: 'mid',\n",
       " 195: 'jump',\n",
       " 196: 'studio',\n",
       " 197: 'sunlight',\n",
       " 198: 'coming',\n",
       " 199: 'through',\n",
       " 200: 'practice',\n",
       " 201: 'wonderful',\n",
       " 202: 'form',\n",
       " 203: 'girls',\n",
       " 204: 'leaping',\n",
       " 205: 'simultaneously',\n",
       " 206: 'dance',\n",
       " 207: 'room',\n",
       " 208: 'bending',\n",
       " 209: 'feet',\n",
       " 210: 'class',\n",
       " 211: 'sneakers',\n",
       " 212: 'midair',\n",
       " 213: 'flight',\n",
       " 214: 'concrete',\n",
       " 215: 'casually',\n",
       " 216: 'stairway',\n",
       " 217: 'outdoors',\n",
       " 218: 'stone',\n",
       " 219: 'wall',\n",
       " 220: 'behind',\n",
       " 221: 'them',\n",
       " 222: 'not',\n",
       " 223: 'staircase',\n",
       " 224: 'excited',\n",
       " 225: 'faces',\n",
       " 226: 'dog',\n",
       " 227: 'spots',\n",
       " 228: 'staring',\n",
       " 229: 'each',\n",
       " 230: 'tri',\n",
       " 231: 'colored',\n",
       " 232: 'road',\n",
       " 233: 'dogs',\n",
       " 234: 'different',\n",
       " 235: 'looking',\n",
       " 236: 'pavement',\n",
       " 237: 'moving',\n",
       " 238: 'toward',\n",
       " 239: 'spotted',\n",
       " 240: 'fighting',\n",
       " 241: 'reflective',\n",
       " 242: 'safety',\n",
       " 243: 'clothes',\n",
       " 244: 'protection',\n",
       " 245: 'drives',\n",
       " 246: 'john',\n",
       " 247: 'deere',\n",
       " 248: 'tractor',\n",
       " 249: 'driver',\n",
       " 250: 'wears',\n",
       " 251: 'see',\n",
       " 252: 'clothing',\n",
       " 253: 'neon',\n",
       " 254: 'orange',\n",
       " 255: 'uniform',\n",
       " 256: 'driving',\n",
       " 257: 'headphones',\n",
       " 258: 'paved',\n",
       " 259: 'main',\n",
       " 260: 'country',\n",
       " 261: 'some',\n",
       " 262: 'women',\n",
       " 263: 'front',\n",
       " 264: 'bus',\n",
       " 265: 'buildings',\n",
       " 266: 'it',\n",
       " 267: 'stand',\n",
       " 268: 'city',\n",
       " 269: 'group',\n",
       " 270: 'wait',\n",
       " 271: 'glasses',\n",
       " 272: 'putting',\n",
       " 273: 'powder',\n",
       " 274: 'cake',\n",
       " 275: 'using',\n",
       " 276: 'lady',\n",
       " 277: 'onto',\n",
       " 278: 'jacket',\n",
       " 279: 'chocolate',\n",
       " 280: 'pan',\n",
       " 281: 'small',\n",
       " 282: 'grass',\n",
       " 283: 'plays',\n",
       " 284: 'canvas',\n",
       " 285: 'rainbow',\n",
       " 286: 'covered',\n",
       " 287: 'paint',\n",
       " 288: 'painted',\n",
       " 289: 'bowl',\n",
       " 290: 'pigtails',\n",
       " 291: 'painting',\n",
       " 292: 'sleeping',\n",
       " 293: 'bench',\n",
       " 294: 'next',\n",
       " 295: 'lays',\n",
       " 296: 'which',\n",
       " 297: 'also',\n",
       " 298: 'tied',\n",
       " 299: 'laying',\n",
       " 300: 'leash',\n",
       " 301: 'ground',\n",
       " 302: 'shirtless',\n",
       " 303: 'lies',\n",
       " 304: 'park',\n",
       " 305: 'adults',\n",
       " 306: 'inside',\n",
       " 307: 'home',\n",
       " 308: 'chairs',\n",
       " 309: 'arranged',\n",
       " 310: 'circle',\n",
       " 311: 'type',\n",
       " 312: 'musical',\n",
       " 313: 'instruments',\n",
       " 314: 'musicians',\n",
       " 315: 'practicing',\n",
       " 316: 'sheet',\n",
       " 317: 'music',\n",
       " 318: '(',\n",
       " 319: 'flutes',\n",
       " 320: ')',\n",
       " 321: 'living',\n",
       " 322: 'gathered',\n",
       " 323: 'talk',\n",
       " 324: 'about',\n",
       " 325: 'favorite',\n",
       " 326: 'tunes',\n",
       " 327: 'both',\n",
       " 328: 'elderly',\n",
       " 329: 'stringed',\n",
       " 330: 'instrument',\n",
       " 331: 'least',\n",
       " 332: 'play',\n",
       " 333: 'bunch',\n",
       " 334: 'as',\n",
       " 335: 'they',\n",
       " 336: 'read',\n",
       " 337: 'off',\n",
       " 338: 'performing',\n",
       " 339: 'person',\n",
       " 340: 'alone',\n",
       " 341: 'has',\n",
       " 342: 'broken',\n",
       " 343: 'roadway',\n",
       " 344: 'washed',\n",
       " 345: 'bridge',\n",
       " 346: 'surveys',\n",
       " 347: 't',\n",
       " 348: 'looks',\n",
       " 349: 'surrounded',\n",
       " 350: 'crowd',\n",
       " 351: 'metro',\n",
       " 352: 'station',\n",
       " 353: 'entrance',\n",
       " 354: 'area',\n",
       " 355: 'goatee',\n",
       " 356: 'latex',\n",
       " 357: 'gloves',\n",
       " 358: 'tattoo',\n",
       " 359: 'gun',\n",
       " 360: 'place',\n",
       " 361: 'back',\n",
       " 362: 'upper',\n",
       " 363: 'giving',\n",
       " 364: 'getting',\n",
       " 365: 'children',\n",
       " 366: 'boy',\n",
       " 367: 'writing',\n",
       " 368: 'sit',\n",
       " 369: 'seesaw',\n",
       " 370: 'sand',\n",
       " 371: 'teeter',\n",
       " 372: 'totter',\n",
       " 373: '2',\n",
       " 374: 'kids',\n",
       " 375: 'vest',\n",
       " 376: 'intersection',\n",
       " 377: 'flag',\n",
       " 378: 'caution',\n",
       " 379: 'waving',\n",
       " 380: 'bright',\n",
       " 381: 'corner',\n",
       " 382: 'spray',\n",
       " 383: 'construction',\n",
       " 384: 'worker',\n",
       " 385: 'red',\n",
       " 386: 'pierced',\n",
       " 387: 'ears',\n",
       " 388: 'beer',\n",
       " 389: 'can',\n",
       " 390: 'starring',\n",
       " 391: 'something',\n",
       " 392: 'long',\n",
       " 393: 'beret',\n",
       " 394: 'beige',\n",
       " 395: 'raincoat',\n",
       " 396: 'marketplace',\n",
       " 397: 'scenery',\n",
       " 398: 'artists',\n",
       " 399: 'paintings',\n",
       " 400: 'busy',\n",
       " 401: 'sidewalk',\n",
       " 402: 'studying',\n",
       " 403: 'scene',\n",
       " 404: 'public',\n",
       " 405: 'others',\n",
       " 406: 'who',\n",
       " 407: 'passerby',\n",
       " 408: 'admiring',\n",
       " 409: 'outdoor',\n",
       " 410: 'art',\n",
       " 411: 'fair',\n",
       " 412: 'foot',\n",
       " 413: 'basket',\n",
       " 414: 'pants',\n",
       " 415: 'pushing',\n",
       " 416: 'cart',\n",
       " 417: 'janitor',\n",
       " 418: 'dolly',\n",
       " 419: 'tools',\n",
       " 420: 'ropes',\n",
       " 421: 'playground',\n",
       " 422: 'climbs',\n",
       " 423: 'rope',\n",
       " 424: 'roping',\n",
       " 425: 'net',\n",
       " 426: 'end',\n",
       " 427: 'traveling',\n",
       " 428: 'flower',\n",
       " 429: 'teen',\n",
       " 430: 'unknown',\n",
       " 431: 'object',\n",
       " 432: 'for',\n",
       " 433: 'photographers',\n",
       " 434: 'train',\n",
       " 435: 'crane',\n",
       " 436: 'you',\n",
       " 437: 'know',\n",
       " 438: 'i',\n",
       " 439: 'am',\n",
       " 440: 'like',\n",
       " 441: 'blond',\n",
       " 442: 'yellow',\n",
       " 443: 'gazing',\n",
       " 444: 'pole',\n",
       " 445: 'vault',\n",
       " 446: 'determined',\n",
       " 447: 'sky',\n",
       " 448: 'baseball',\n",
       " 449: 'cap',\n",
       " 450: 'bathroom',\n",
       " 451: 'coffee',\n",
       " 452: 'mug',\n",
       " 453: 'ball',\n",
       " 454: 'cup',\n",
       " 455: 'between',\n",
       " 456: 'posing',\n",
       " 457: 'multicolored',\n",
       " 458: 'background',\n",
       " 459: 'sunset',\n",
       " 460: 'clear',\n",
       " 461: 'skies',\n",
       " 462: 'sun',\n",
       " 463: 'setting',\n",
       " 464: 'silhouettes',\n",
       " 465: 'decorate',\n",
       " 466: 'horizon',\n",
       " 467: 'sets',\n",
       " 468: 'restaurant',\n",
       " 469: 'glass',\n",
       " 470: 'table',\n",
       " 471: 'drink',\n",
       " 472: 'drinking',\n",
       " 473: 'old',\n",
       " 474: 'having',\n",
       " 475: 'running',\n",
       " 476: 'grassy',\n",
       " 477: 'fence',\n",
       " 478: 'boston',\n",
       " 479: 'terrier',\n",
       " 480: 'lush',\n",
       " 481: 'runs',\n",
       " 482: 'officer',\n",
       " 483: 'van',\n",
       " 484: 'police',\n",
       " 485: 'security',\n",
       " 486: 'watch',\n",
       " 487: 'policeman',\n",
       " 488: 'german',\n",
       " 489: 'shepherd',\n",
       " 490: 'stops',\n",
       " 491: 'search',\n",
       " 492: '\"',\n",
       " 493: 'conditions',\n",
       " 494: 'snow',\n",
       " 495: 'seem',\n",
       " 496: 'almost',\n",
       " 497: 'cold',\n",
       " 498: 'weather',\n",
       " 499: 'heavy',\n",
       " 500: 'riding',\n",
       " 501: 'bicycle',\n",
       " 502: 'suburban',\n",
       " 503: 'neighborhood',\n",
       " 504: 'rides',\n",
       " 505: 'bike',\n",
       " 506: 'snowy',\n",
       " 507: 'tie',\n",
       " 508: 'slacks',\n",
       " 509: 'converse',\n",
       " 510: 'open',\n",
       " 511: '5',\n",
       " 512: 'suits',\n",
       " 513: 'short',\n",
       " 514: 'sleeved',\n",
       " 515: 'ties',\n",
       " 516: 'stop',\n",
       " 517: 'take',\n",
       " 518: 'break',\n",
       " 519: 'business',\n",
       " 520: 'tan',\n",
       " 521: 'backwards',\n",
       " 522: 'factory',\n",
       " 523: 'older',\n",
       " 524: 'too',\n",
       " 525: 'photograph',\n",
       " 526: 'camp',\n",
       " 527: 'among',\n",
       " 528: 'machines',\n",
       " 529: 'works',\n",
       " 530: 'machinery',\n",
       " 531: 'work',\n",
       " 532: 'caucasian',\n",
       " 533: 'skinned',\n",
       " 534: 'sleeveless',\n",
       " 535: 'conveyor',\n",
       " 536: 'packing',\n",
       " 537: 'jars',\n",
       " 538: 'candles',\n",
       " 539: 'boxes',\n",
       " 540: 'sorting',\n",
       " 541: 'warehouse',\n",
       " 542: 'assisting',\n",
       " 543: 'employee',\n",
       " 544: 'assembly',\n",
       " 545: 'line',\n",
       " 546: 'outfit',\n",
       " 547: 'broom',\n",
       " 548: 'traditional',\n",
       " 549: 'architecture',\n",
       " 550: 'baby',\n",
       " 551: 'bottoms',\n",
       " 552: 'remove',\n",
       " 553: 'dirt',\n",
       " 554: 'kimono',\n",
       " 555: 'sweep',\n",
       " 556: 'sweeping',\n",
       " 557: 'walkway',\n",
       " 558: 'florescent',\n",
       " 559: 'vests',\n",
       " 560: 'parked',\n",
       " 561: 'cars',\n",
       " 562: 'converses',\n",
       " 563: 'seen',\n",
       " 564: 'leans',\n",
       " 565: 'car',\n",
       " 566: 'watching',\n",
       " 567: 'row',\n",
       " 568: 'waiting',\n",
       " 569: 'go',\n",
       " 570: 'tourist',\n",
       " 571: 'eating',\n",
       " 572: 'snack',\n",
       " 573: 'toddlers',\n",
       " 574: 'infants',\n",
       " 575: 'female',\n",
       " 576: 'babies',\n",
       " 577: 'chips',\n",
       " 578: 'silver',\n",
       " 579: 'mobile',\n",
       " 580: 'weird',\n",
       " 581: 'vehicle',\n",
       " 582: 'plaza',\n",
       " 583: 'segway',\n",
       " 584: 'showing',\n",
       " 585: 'product',\n",
       " 586: 'modern',\n",
       " 587: '?',\n",
       " 588: 'approaches',\n",
       " 589: 'strange',\n",
       " 590: 'containing',\n",
       " 591: 'onlookers',\n",
       " 592: 'observe',\n",
       " 593: 'roped',\n",
       " 594: 'barrier',\n",
       " 595: 'watches',\n",
       " 596: 'single',\n",
       " 597: '4',\n",
       " 598: 'wheeled',\n",
       " 599: 'bride',\n",
       " 600: 'groom',\n",
       " 601: 'side',\n",
       " 602: 'focus',\n",
       " 603: 'pathway',\n",
       " 604: 'brick',\n",
       " 605: 'beautiful',\n",
       " 606: 'new',\n",
       " 607: 'husband',\n",
       " 608: 'recently',\n",
       " 609: 'married',\n",
       " 610: 'couple',\n",
       " 611: 'pose',\n",
       " 612: 'arm',\n",
       " 613: 'nintendo',\n",
       " 614: 'mcdonald',\n",
       " 615: 'video',\n",
       " 616: 'game',\n",
       " 617: 'kiosk',\n",
       " 618: 'kid',\n",
       " 619: 'water',\n",
       " 620: 'head',\n",
       " 621: 'turned',\n",
       " 622: 'shore',\n",
       " 623: 'shaking',\n",
       " 624: 'shakes',\n",
       " 625: 'edge',\n",
       " 626: 'beach',\n",
       " 627: 'its',\n",
       " 628: 'picnic',\n",
       " 629: 'tables',\n",
       " 630: 'enjoying',\n",
       " 631: 'day',\n",
       " 632: 'reunion',\n",
       " 633: 'full',\n",
       " 634: 'swing',\n",
       " 635: 'moon',\n",
       " 636: 'bounce',\n",
       " 637: 'barbecue',\n",
       " 638: 'or',\n",
       " 639: 'spanish',\n",
       " 640: 'pass',\n",
       " 641: 'sunglasses',\n",
       " 642: 'puts',\n",
       " 643: 'blouse',\n",
       " 644: 'traffic',\n",
       " 645: 'seated',\n",
       " 646: 'balloon',\n",
       " 647: 'design',\n",
       " 648: 'burger',\n",
       " 649: 'touching',\n",
       " 650: 'coolers',\n",
       " 651: 'enjoys',\n",
       " 652: 'sandwich',\n",
       " 653: 'student',\n",
       " 654: 'downward',\n",
       " 655: 'kick',\n",
       " 656: 'board',\n",
       " 657: 'held',\n",
       " 658: 'karate',\n",
       " 659: 'instructor',\n",
       " 660: 'wood',\n",
       " 661: 'half',\n",
       " 662: 'kicking',\n",
       " 663: 'stick',\n",
       " 664: 'that',\n",
       " 665: 'do',\n",
       " 666: 'breaking',\n",
       " 667: 'boards',\n",
       " 668: 'demonstrating',\n",
       " 669: 'martial',\n",
       " 670: 'arts',\n",
       " 671: 'youngsters',\n",
       " 672: 'crouched',\n",
       " 673: 'mat',\n",
       " 674: 'during',\n",
       " 675: 'competition',\n",
       " 676: 'jumps',\n",
       " 677: 'students',\n",
       " 678: 'demonstration',\n",
       " 679: 'perform',\n",
       " 680: 'balconies',\n",
       " 681: 'pipe',\n",
       " 682: 'towards',\n",
       " 683: 'lower',\n",
       " 684: 'balcony',\n",
       " 685: 'liquid',\n",
       " 686: 'sweatshirt',\n",
       " 687: 'reaching',\n",
       " 688: 'hand',\n",
       " 689: 'bottle',\n",
       " 690: 'below',\n",
       " 691: 'pouring',\n",
       " 692: 'contents',\n",
       " 693: 'shielding',\n",
       " 694: 'himself',\n",
       " 695: 'trying',\n",
       " 696: 'paper',\n",
       " 697: 'block',\n",
       " 698: 'shades',\n",
       " 699: 'eyes',\n",
       " 700: 'face',\n",
       " 701: 'carrying',\n",
       " 702: 'backs',\n",
       " 703: 'sunny',\n",
       " 704: 'nice',\n",
       " 705: 'walk',\n",
       " 706: 'stroll',\n",
       " 707: 'rock',\n",
       " 708: 'overalls',\n",
       " 709: 'smiles',\n",
       " 710: 'stony',\n",
       " 711: 'collar',\n",
       " 712: 'fallen',\n",
       " 713: 'tree',\n",
       " 714: 'leaps',\n",
       " 715: 'log',\n",
       " 716: 'jumped',\n",
       " 717: 'stump',\n",
       " 718: 'crossing',\n",
       " 719: 'gathering',\n",
       " 720: 'across',\n",
       " 721: 'gentleman',\n",
       " 722: 'bikes',\n",
       " 723: 'body',\n",
       " 724: 'river',\n",
       " 725: 'barefooted',\n",
       " 726: 'olive',\n",
       " 727: 'shorts',\n",
       " 728: 'grilling',\n",
       " 729: 'hotdogs',\n",
       " 730: 'grill',\n",
       " 731: 'plastic',\n",
       " 732: 'sausages',\n",
       " 733: 'prepares',\n",
       " 734: 'he',\n",
       " 735: 'grills',\n",
       " 736: 'surface',\n",
       " 737: 'field',\n",
       " 738: 'scooter',\n",
       " 739: 'attention',\n",
       " 740: 'those',\n",
       " 741: 'light',\n",
       " 742: 'cross',\n",
       " 743: 'skis',\n",
       " 744: 'framed',\n",
       " 745: 'pictures',\n",
       " 746: 'displaying',\n",
       " 747: 'skier',\n",
       " 748: 'trees',\n",
       " 749: 'artwork',\n",
       " 750: 'sale',\n",
       " 751: 'climbers',\n",
       " 752: 'seven',\n",
       " 753: 'ascending',\n",
       " 754: 'whilst',\n",
       " 755: 'cliff',\n",
       " 756: 'gymnast',\n",
       " 757: 'high',\n",
       " 758: 'air',\n",
       " 759: 'balance',\n",
       " 760: 'beam',\n",
       " 761: 'leotard',\n",
       " 762: 'doing',\n",
       " 763: 'gymnastics',\n",
       " 764: 'audience',\n",
       " 765: 'soars',\n",
       " 766: 'wheeler',\n",
       " 767: 'pool',\n",
       " 768: 'atv',\n",
       " 769: 'rubber',\n",
       " 770: 'miniature',\n",
       " 771: 'lawn',\n",
       " 772: 'quad',\n",
       " 773: 'truck',\n",
       " 774: 'filled',\n",
       " 775: 'cotton',\n",
       " 776: 'substance',\n",
       " 777: 'pile',\n",
       " 778: 'wool',\n",
       " 779: 'loading',\n",
       " 780: 'load',\n",
       " 781: 'headscarf',\n",
       " 782: 'scenic',\n",
       " 783: 'view',\n",
       " 784: 'bay',\n",
       " 785: 'pay',\n",
       " 786: 'binoculars',\n",
       " 787: 'viewing',\n",
       " 788: 'deck',\n",
       " 789: 'mounted',\n",
       " 790: 'telescope',\n",
       " 791: 'windbreaker',\n",
       " 792: 'though',\n",
       " 793: 'rooftop',\n",
       " 794: 'uses',\n",
       " 795: 'ticket',\n",
       " 796: 'stuck',\n",
       " 797: 'plane',\n",
       " 798: 'examining',\n",
       " 799: 'airplane',\n",
       " 800: 'nose',\n",
       " 801: 'away',\n",
       " 802: 'sprinkler',\n",
       " 803: 'chases',\n",
       " 804: 'hose',\n",
       " 805: 'happily',\n",
       " 806: 'supermarket',\n",
       " 807: 'daughter',\n",
       " 808: 'grocery',\n",
       " 809: 'store',\n",
       " 810: 'stroller',\n",
       " 811: 'catch',\n",
       " 812: 'thrown',\n",
       " 813: 'nearby',\n",
       " 814: 'ready',\n",
       " 815: 'flying',\n",
       " 816: 'mouth',\n",
       " 817: 'after',\n",
       " 818: 'covering',\n",
       " 819: 'part',\n",
       " 820: 'booth',\n",
       " 821: 'sweater',\n",
       " 822: 'get',\n",
       " 823: 'hiking',\n",
       " 824: 'forest',\n",
       " 825: 'where',\n",
       " 826: 'partially',\n",
       " 827: 'wilderness',\n",
       " 828: 'hikers',\n",
       " 829: 'resting',\n",
       " 830: 'patch',\n",
       " 831: 'facial',\n",
       " 832: 'cabinet',\n",
       " 833: 'doors',\n",
       " 834: 'sleeve',\n",
       " 835: 'under',\n",
       " 836: 'aged',\n",
       " 837: 'beard',\n",
       " 838: 'handmade',\n",
       " 839: 'creation',\n",
       " 840: 'floor',\n",
       " 841: 'reading',\n",
       " 842: 'father',\n",
       " 843: 'grown',\n",
       " 844: 'son',\n",
       " 845: 'camping',\n",
       " 846: 'trip',\n",
       " 847: 'wild',\n",
       " 848: 'items',\n",
       " 849: 'bearded',\n",
       " 850: 'map',\n",
       " 851: 'traveler',\n",
       " 852: 'lake',\n",
       " 853: 'lone',\n",
       " 854: 'duck',\n",
       " 855: 'swimming',\n",
       " 856: 'waves',\n",
       " 857: 'facing',\n",
       " 858: 'skyline',\n",
       " 859: 'waters',\n",
       " 860: 'big',\n",
       " 861: 'infant',\n",
       " 862: 'being',\n",
       " 863: 'male',\n",
       " 864: 'pond',\n",
       " 865: 'care',\n",
       " 866: 'along',\n",
       " 867: 'newborn',\n",
       " 868: 'shelter',\n",
       " 869: 'bicycles',\n",
       " 870: 'curved',\n",
       " 871: 'roof',\n",
       " 872: 'wagon',\n",
       " 873: 'nighttime',\n",
       " 874: 'dome',\n",
       " 875: 'beside',\n",
       " 876: 'lab',\n",
       " 877: 'tags',\n",
       " 878: 'this',\n",
       " 879: 'splashing',\n",
       " 880: 'surf',\n",
       " 881: 'splashes',\n",
       " 882: 'drilling',\n",
       " 883: 'frozen',\n",
       " 884: 'ice',\n",
       " 885: 'hole',\n",
       " 886: 'fishing',\n",
       " 887: 'making',\n",
       " 888: 'turn',\n",
       " 889: 'soft',\n",
       " 890: 'sandy',\n",
       " 891: 'climber',\n",
       " 892: 'scaling',\n",
       " 893: 'picks',\n",
       " 894: 'scale',\n",
       " 895: 'waterfall',\n",
       " 896: 'meadow',\n",
       " 897: 'ocean',\n",
       " 898: 'path',\n",
       " 899: 'attire',\n",
       " 900: 'shovels',\n",
       " 901: 'all',\n",
       " 902: 'shoveling',\n",
       " 903: 'sidewalks',\n",
       " 904: 'wedding',\n",
       " 905: 'flowers',\n",
       " 906: 'reception',\n",
       " 907: 'smile',\n",
       " 908: 'cutting',\n",
       " 909: 'snowmobile',\n",
       " 910: 'riders',\n",
       " 911: 'helmets',\n",
       " 912: 'goggles',\n",
       " 913: 'clearing',\n",
       " 914: ';',\n",
       " 915: 'left',\n",
       " 916: 'right',\n",
       " 917: 'winter',\n",
       " 918: 'jackets',\n",
       " 919: 'ski',\n",
       " 920: 'gather',\n",
       " 921: 'carries',\n",
       " 922: 'wet',\n",
       " 923: 'item',\n",
       " 924: 'rows',\n",
       " 925: 'vegetables',\n",
       " 926: 'sell',\n",
       " 927: 'vegetable',\n",
       " 928: 'harvest',\n",
       " 929: 'lay',\n",
       " 930: 'blankets',\n",
       " 931: 'market',\n",
       " 932: 'villagers',\n",
       " 933: 'selling',\n",
       " 934: 'crops',\n",
       " 935: 'these',\n",
       " 936: 'very',\n",
       " 937: 'onions',\n",
       " 938: 'band',\n",
       " 939: 'singer',\n",
       " 940: 'tattoos',\n",
       " 941: 'crowded',\n",
       " 942: 'concert',\n",
       " 943: 'approaching',\n",
       " 944: 'shouting',\n",
       " 945: 'microphone',\n",
       " 946: 'listening',\n",
       " 947: 'sings',\n",
       " 948: 'sign',\n",
       " 949: 'says',\n",
       " 950: '13',\n",
       " 951: 'punk',\n",
       " 952: 'rocker',\n",
       " 953: 'screaming',\n",
       " 954: 'stage',\n",
       " 955: 'striped',\n",
       " 956: 'skateboard',\n",
       " 957: 'skateboarding',\n",
       " 958: 'skate',\n",
       " 959: 'trick',\n",
       " 960: 'life',\n",
       " 961: 'rowing',\n",
       " 962: 'canoe',\n",
       " 963: 'kayak',\n",
       " 964: 'ride',\n",
       " 965: 'seems',\n",
       " 966: 'be',\n",
       " 967: 'laughing',\n",
       " 968: 'porch',\n",
       " 969: 'straight',\n",
       " 970: 'ladies',\n",
       " 971: 'site',\n",
       " 972: 'installing',\n",
       " 973: 'post',\n",
       " 974: 'house',\n",
       " 975: 'atop',\n",
       " 976: 'younger',\n",
       " 977: 'luggage',\n",
       " 978: 'billboard',\n",
       " 979: 'suitcase',\n",
       " 980: 'advertisement',\n",
       " 981: 'picture',\n",
       " 982: 'airport',\n",
       " 983: 'sleeves',\n",
       " 984: 'couch',\n",
       " 985: 'napping',\n",
       " 986: 'shoulders',\n",
       " 987: 'mom',\n",
       " 988: 'mother',\n",
       " 989: 'gay',\n",
       " 990: 'pride',\n",
       " 991: 'parade',\n",
       " 992: 'hold',\n",
       " 993: 'flags',\n",
       " 994: 'show',\n",
       " 995: 'support',\n",
       " 996: 'march',\n",
       " 997: 'color',\n",
       " 998: 'oriental',\n",
       " 999: 'fish',\n",
       " ...}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.291602Z",
     "start_time": "2025-07-24T21:35:19.282136Z"
    }
   },
   "cell_type": "code",
   "source": "from torchvision import transforms",
   "id": "4165c4ada9b78947",
   "outputs": [],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.354161Z",
     "start_time": "2025-07-24T21:35:19.340389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms= transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   # ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]     # ImageNet std\n",
    "    )\n",
    "])"
   ],
   "id": "21da53f94c8b8b34",
   "outputs": [],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.577998Z",
     "start_time": "2025-07-24T21:35:19.402375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = FlickerDataset(\n",
    "    root_dir=r\"C:\\Users\\swaya\\Desktop\\Timepass\\python\\archive\\flickr30k_images\\flickr30k_images\",  # folder of .jpgs\n",
    "    caption_file=\"captions.csv\",\n",
    "    vocab=voab,\n",
    "    transform=transforms\n",
    ")\n"
   ],
   "id": "9a355ba280dce8b6",
   "outputs": [],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.640841Z",
     "start_time": "2025-07-24T21:35:19.625096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img, caption = dataset[0]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Caption indices: {caption}\")\n",
    "print(f\"Decoded: {[voab.itos[token.item()] for token in caption]}\")\n"
   ],
   "id": "8d32c52779c6460",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 224, 224])\n",
      "Caption indices: tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "        21,  2])\n",
      "Decoded: ['<SOS>', ' ', 'two', 'young', 'guys', 'with', 'shaggy', 'hair', 'look', 'at', 'their', 'hands', 'while', 'hanging', 'out', 'in', 'the', 'yard', '.', '<EOS>']\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.707804Z",
     "start_time": "2025-07-24T21:35:19.688284Z"
    }
   },
   "cell_type": "code",
   "source": "img=df['images']",
   "id": "cd49f555597948f2",
   "outputs": [],
   "execution_count": 209
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.770246Z",
     "start_time": "2025-07-24T21:35:19.753645Z"
    }
   },
   "cell_type": "code",
   "source": "img",
   "id": "fabcd71710b9a198",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         1000092795.jpg\n",
       "2         1000092795.jpg\n",
       "3         1000092795.jpg\n",
       "4         1000092795.jpg\n",
       "5         1000092795.jpg\n",
       "               ...      \n",
       "158911     998845445.jpg\n",
       "158912     998845445.jpg\n",
       "158913     998845445.jpg\n",
       "158914     998845445.jpg\n",
       "158915     998845445.jpg\n",
       "Name: images, Length: 158915, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 210
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.881283Z",
     "start_time": "2025-07-24T21:35:19.865520Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "98e7b865ed17fb3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:19.986683Z",
     "start_time": "2025-07-24T21:35:19.971345Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "1aaa9a537c3b373e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                images                                            caption\n",
       "1       1000092795.jpg   Two young guys with shaggy hair look at their...\n",
       "2       1000092795.jpg   Two young , White males are outside near many...\n",
       "3       1000092795.jpg   Two men in green shirts are standing in a yard .\n",
       "4       1000092795.jpg       A man in a blue shirt standing in a garden .\n",
       "5       1000092795.jpg            Two friends enjoy time spent together .\n",
       "...                ...                                                ...\n",
       "158911   998845445.jpg   A man in shorts and a Hawaiian shirt leans ov...\n",
       "158912   998845445.jpg   A young man hanging over the side of a boat ,...\n",
       "158913   998845445.jpg   A man is leaning off of the side of a blue an...\n",
       "158914   998845445.jpg   A man riding a small boat in a harbor , with ...\n",
       "158915   998845445.jpg   A man on a moored blue and white boat with hi...\n",
       "\n",
       "[158915 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158911</th>\n",
       "      <td>998845445.jpg</td>\n",
       "      <td>A man in shorts and a Hawaiian shirt leans ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158912</th>\n",
       "      <td>998845445.jpg</td>\n",
       "      <td>A young man hanging over the side of a boat ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158913</th>\n",
       "      <td>998845445.jpg</td>\n",
       "      <td>A man is leaning off of the side of a blue an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158914</th>\n",
       "      <td>998845445.jpg</td>\n",
       "      <td>A man riding a small boat in a harbor , with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158915</th>\n",
       "      <td>998845445.jpg</td>\n",
       "      <td>A man on a moored blue and white boat with hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158915 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 211
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:20.225952Z",
     "start_time": "2025-07-24T21:35:20.210290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch = list of (image, caption_tensor)\n",
    "        images = [item[0].unsqueeze(0) for item in batch]  # shape: [1, 3, H, W]\n",
    "        captions = [item[1] for item in batch]  # shape: variable lengths\n",
    "\n",
    "        images = torch.cat(images, dim=0)  # Now shape: [batch_size, 3, H, W]\n",
    "        captions = pad_sequence(captions, batch_first=True, padding_value=self.pad_idx)\n",
    "\n",
    "        return images, captions\n"
   ],
   "id": "a1582fe7c8dc58b5",
   "outputs": [],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:20.345346Z",
     "start_time": "2025-07-24T21:35:20.329450Z"
    }
   },
   "cell_type": "code",
   "source": "pad_idx=voab.stoi[\"<PAD>\"]",
   "id": "5f7b00a16c0fbaf4",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:20.714423Z",
     "start_time": "2025-07-24T21:35:20.698268Z"
    }
   },
   "cell_type": "code",
   "source": "pad_idx",
   "id": "60c9bf365e474c49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:20.782149Z",
     "start_time": "2025-07-24T21:35:20.766162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Data_loader=DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=MyCollate(pad_idx=pad_idx)\n",
    ")"
   ],
   "id": "939d30756ab9dec2",
   "outputs": [],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:40:40.765117Z",
     "start_time": "2025-07-24T21:40:40.749087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        \"\"\"\n",
    "        Initializes the EncoderCNN.\n",
    "        The input size for the fully connected layer is determined automatically.\n",
    "        \"\"\"\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Create a dummy input tensor to pass through the CNN\n",
    "        # to determine the shape of the output.\n",
    "        # The input is (batch_size, channels, height, width)\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            cnn_output = self.cnn(dummy_input)\n",
    "\n",
    "        # Calculate the number of features after the conv layers\n",
    "        # cnn_output.shape will be (1, 64, 28, 28)\n",
    "        # We flatten this to get the input size for the linear layer\n",
    "        flattened_size = cnn_output.view(1, -1).size(1)\n",
    "\n",
    "        # Now, initialize the fully connected layer with the correct input size\n",
    "        self.fc = nn.Linear(flattened_size, embed_size)\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"The forward pass for the encoder.\"\"\"\n",
    "        # 1. Pass images through convolutional layers\n",
    "        features = self.cnn(images)\n",
    "\n",
    "        # 2. Flatten the features. The -1 infers the size from other dimensions.\n",
    "        # Shape changes from (batch_size, 64, 28, 28) to (batch_size, 50176)\n",
    "        features = features.view(features.size(0), -1)\n",
    "\n",
    "        # 3. Pass flattened features through the fully connected layer\n",
    "        features = self.fc(features)\n",
    "\n",
    "        return features\n",
    "\n",
    "# --- How to use it ---\n",
    "# embed_size = 256\n",
    "# encoder = EncoderCNN(embed_size)\n",
    "# print(encoder)\n",
    "\n",
    "# # Test with a dummy batch of images\n",
    "# dummy_images = torch.randn(32, 3, 224, 224) # batch_size=32\n",
    "# output_features = encoder(dummy_images)\n",
    "# print(f\"Output shape: {output_features.shape}\") # Should be (32, 256)"
   ],
   "id": "5c39c286f263ba6e",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:40:41.486878Z",
     "start_time": "2025-07-24T21:40:41.471412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        embeddings = self.embed(captions[:, :-1])  # remove <EOS>\n",
    "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs\n"
   ],
   "id": "b227911238d2865a",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:40:42.074168Z",
     "start_time": "2025-07-24T21:40:41.961019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "vocab_size = len(voab)\n",
    "num_layers = 1\n",
    "\n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=voab.stoi[\"<PAD>\"])\n",
    "params = list(decoder.parameters()) + list(encoder.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.001)\n"
   ],
   "id": "3889ae473fb117c9",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:40:43.125341Z",
     "start_time": "2025-07-24T21:40:42.572894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(3):\n",
    "    for idx, (imgs, captions) in enumerate(Data_loader):\n",
    "        features = encoder(imgs)\n",
    "        # Slice the outputs to match the captions' length before reshaping\n",
    "        outputs = outputs[:, :-1, :]\n",
    "\n",
    "        loss = criterion(outputs.reshape(-1, outputs.shape[2]), captions[:, 1:].reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}], Step [{idx}], Loss: {loss.item():.4f}\")\n"
   ],
   "id": "a914d4287119a880",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (736) to match target batch_size (928).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[226], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Slice the outputs to match the captions' length before reshaping\u001B[39;00m\n\u001B[0;32m      5\u001B[0m outputs \u001B[38;5;241m=\u001B[39m outputs[:, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :]\n\u001B[1;32m----> 7\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptions\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      9\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1294\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1300\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3479\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3478\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3479\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3480\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3481\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3482\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3483\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3484\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3486\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected input batch_size (736) to match target batch_size (928)."
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:40:43.335414Z",
     "start_time": "2025-07-24T21:40:43.245033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "encoder = EncoderCNN(embed_size=256)\n",
    "output = encoder(dummy_input)\n",
    "print(output.shape)\n"
   ],
   "id": "7909c4db0c0a8b6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:21.766504900Z",
     "start_time": "2025-07-24T21:30:04.644355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = EncoderCNN(embed_size=256)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "output = encoder(dummy_input)\n",
    "print(output.shape)  # should be [1, 256]\n"
   ],
   "id": "9a68374150fbc5a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T21:35:21.766504900Z",
     "start_time": "2025-07-24T21:29:28.901423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened = output.view(1, -1)\n",
    "print(\"Flattened shape:\", flattened.shape)\n"
   ],
   "id": "b891a6391c7fadf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened shape: torch.Size([1, 50176])\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b86386c147e38c70"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
